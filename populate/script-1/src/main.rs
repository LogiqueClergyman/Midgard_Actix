mod model;
use bigdecimal::BigDecimal;
use chrono::{NaiveDate, Utc};
pub use model::AssetPriceHistory;
use reqwest::get;
use serde_json::Value;
use shared::{create_db_pool, run_migrations};
use sqlx::Error;
use std::{default, str::FromStr};
use tokio::{signal::ctrl_c, sync::Mutex};
static LAST_SUCCESSFUL_ENTRY: std::sync::Mutex<i64> = std::sync::Mutex::new(0);

#[tokio::main]
async fn main() {
    let pool = create_db_pool().await.unwrap();
    let pool = pool.lock().await;
    run_migrations(&pool).await.unwrap();
    let res = fetch_and_insert_data(&pool).await;
    update_last_successful_entry(&pool).await.unwrap();
    if let Err(e) = res {
        eprintln!("Error: {:?}", e);
    }
}
async fn fetch_and_insert_data(pool: &sqlx::PgPool) -> Result<(), Error> {
    let start_date = NaiveDate::from_ymd_opt(2024, 10, 1)
        .unwrap_or_else(|| panic!("Invalid date"))
        .and_hms_opt(0, 0, 0)
        .unwrap();

    let mut from_time = start_date.timestamp();
    // Retrieve the last successful entry's endTime from the FetchState table, defaulting to 1 Oct 2024 if not found

    let last_successful_entry = get_last_successful_entry(&pool).await.unwrap_or_else(|_| {
        println!("{:?}", start_date.timestamp());
        start_date.timestamp() // Make sure to convert to DateTime<Utc>
    });
    from_time = last_successful_entry;
    // println!("{:?}", from_time);
    // Set end time as the current time
    let end_time = Utc::now().timestamp();
    // println!("{:?}", end_time);
    let mut count = 0;
    // Loop to fetch data in chunks of 400
    loop {
        // Construct the API request URL with `from_time` and `count=400`
        let url = format!(
            "https://midgard.ninerealms.com/v2/history/depths/BTC.BTC?interval=hour&from={}&count=100", 
            from_time
        );
        println!("{:?}", url);
        // Make the API request
        let response: Value = get(&url).await.unwrap().json().await.unwrap();
        // println!("{:?}", response);
        if let Some(intervals) = response["intervals"].as_array() {
            // Loop through the data and insert each entry into the database
            for entry in intervals {
                let asset_price_history = AssetPriceHistory {
                    assetDepth: entry["assetDepth"]
                        .as_str()
                        .unwrap()
                        .parse::<i64>()
                        .unwrap(),
                    assetPrice: entry["assetPrice"]
                        .as_str()
                        .unwrap()
                        .parse::<f64>()
                        .unwrap(),
                    assetPriceUSD: entry["assetPriceUSD"]
                        .as_str()
                        .unwrap()
                        .parse::<f64>()
                        .unwrap(),
                    liquidityUnits: entry["liquidityUnits"]
                        .as_str()
                        .unwrap()
                        .parse::<i64>()
                        .unwrap(),
                    luvi: entry["luvi"].as_str().unwrap().parse::<f64>().unwrap(),
                    membersCount: entry["membersCount"]
                        .as_str()
                        .unwrap()
                        .parse::<i32>()
                        .unwrap(),
                    runeDepth: entry["runeDepth"].as_str().unwrap().parse::<i64>().unwrap(),
                    synthSupply: entry["synthSupply"]
                        .as_str()
                        .unwrap()
                        .parse::<i64>()
                        .unwrap(),
                    synthUnits: entry["synthUnits"]
                        .as_str()
                        .unwrap()
                        .parse::<i64>()
                        .unwrap(),
                    units: entry["units"].as_str().unwrap().parse::<i64>().unwrap(),
                    startTime: entry["startTime"].as_str().unwrap().parse::<i64>().unwrap(),
                    endTime: entry["endTime"].as_str().unwrap().parse::<i64>().unwrap(),
                    id: None, // This will be auto-generated by PostgreSQL
                };
                // println!("{:?}", asset_price_history);
                match sqlx::query!(
                    r#"
                    INSERT INTO Depth_Price_History (
                        assetDepth, assetPrice, assetPriceUSD, liquidityUnits, luvi,
                        membersCount, runeDepth, synthSupply, synthUnits, units, startTime, endTime
                    )
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
                    "#,
                    asset_price_history.assetDepth,
                    BigDecimal::from_str(&asset_price_history.assetPrice.to_string()).unwrap(),
                    BigDecimal::from_str(&asset_price_history.assetPriceUSD.to_string()).unwrap(),
                    asset_price_history.liquidityUnits,
                    BigDecimal::from_str(&asset_price_history.luvi.to_string()).unwrap(),
                    asset_price_history.membersCount,
                    asset_price_history.runeDepth,
                    asset_price_history.synthSupply,
                    asset_price_history.synthUnits,
                    asset_price_history.units,
                    asset_price_history.startTime,
                    asset_price_history.endTime
                )
                .execute(pool)
                .await
                {
                    Ok(_) => {}
                    Err(e) => {
                        if let sqlx::Error::Database(db_err) = &e {
                            if db_err.code() == Some("23505".into()) {
                                // Skip this entry due to duplicate key error
                                continue;
                            }
                        }
                        return Err(e);
                    }
                };
                // count += 1;
                *LAST_SUCCESSFUL_ENTRY.lock().unwrap() = asset_price_history.endTime;
            }
            let last_entry = intervals.last().unwrap();
            let last_end_time = last_entry["endTime"]
                .as_str()
                .unwrap()
                .parse::<i64>()
                .unwrap();

            // If the `end_time` of the last entry is greater than or equal to current time, we are done
            if last_end_time >= end_time {
                break;
            }

            // Otherwise, update `from_time` to the `end_time` of the last entry
            from_time = last_end_time;
        } else {
            break; // No more data, exit loop
        }
    }
    Ok(())
}

// Fetch the last successful entry's `endTime` from the FetchState table
async fn get_last_successful_entry(pool: &sqlx::PgPool) -> Result<i64, Error> {
    let result = sqlx::query!(
        r#"
        SELECT last_successful_entry FROM fetch_state WHERE table_name = 'depth_price_history'
        "#,
    )
    .fetch_optional(pool)
    .await?;
    let default_value = NaiveDate::from_ymd_opt(2024, 10, 1)
        .unwrap_or_else(|| panic!("Invalid date"))
        .and_hms_opt(0, 0, 0)
        .unwrap()
        .timestamp();
    let res = result.map(|r| r.last_successful_entry).unwrap_or(default_value.into());
    if res == 0 {
        return Ok(default_value.into());
    }
    Ok(res)
}

// Update the `last_successful_entry` in the FetchState table (only once when completed or failed)
async fn update_last_successful_entry(pool: &sqlx::PgPool) -> Result<(), Error> {
    let end_time = *LAST_SUCCESSFUL_ENTRY.lock().unwrap();
    sqlx::query!(
        r#"
        INSERT INTO fetch_state (table_name, last_successful_entry)
        VALUES ('depth_price_history', $1)
        ON CONFLICT (table_name)
        DO UPDATE SET last_successful_entry = EXCLUDED.last_successful_entry
        "#,
        end_time
    )
    .execute(pool)
    .await?;
    Ok(())
}
